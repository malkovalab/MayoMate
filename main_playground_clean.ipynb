{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MayoMate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Environment\n",
    " - Import dependencies\n",
    " - Define hyperparameters\n",
    " - Set up logging\n",
    " - Create directories for outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import logging\n",
    "from mayo import *\n",
    "from mayo.settings import config as cfg\n",
    "from mayo.settings import genotype_dict as genotype_dict_master\n",
    "genotype_dict = genotype_dict_master[cfg[\"genotype_dict\"]]\n",
    "\n",
    "from mayo.settings import haploid_samples as haploid_samples\n",
    "from mayo.settings import haploid_samples_ung1d as haploid_samples_ung1d\n",
    "\n",
    "# Set Reference Chromosomal Intervals for figure drawing and create a DataFrame\n",
    "from mayo.settings import chromosomes as chromosomes\n",
    "df_chr = pd.DataFrame(chromosomes, columns=[\"chromosome\", \"end_position\"])\n",
    "\n",
    "\n",
    "SNP_NUM = cfg[\"SNP_NUM\"]\n",
    "CLUSTER_TYPE_ANALYSIS = cfg[\"CLUSTER_TYPE_ANALYSIS\"]\n",
    "SIG = cfg[\"SIG\"]\n",
    "CLUST_INTER_MUT_MAX = cfg[\"CLUST_INTER_MUT_MAX\"]\n",
    "\n",
    "#CLUSTER_TYPE_ANALYSIS = \"PMACD\" (depricated)\n",
    "#SIG = 'p001_def' # p05, p01, p005, p001_def, p0005, p0001\n",
    "\n",
    "logging.basicConfig(\n",
    "    handlers=[logging.FileHandler(\n",
    "        filename=f'outputs/logs/main_mayo_{SIG}_{SNP_NUM}snp_{CLUSTER_TYPE_ANALYSIS}.log', #main_mayo_2snps.log, main_mayo_1snp.log\n",
    "        encoding='utf-8',\n",
    "        mode='w')],\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s:%(levelname)s:.%(funcName)s: %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "diploid = cfg[\"diploid\"]\n",
    "import BioAid as ba\n",
    "\n",
    "print(f\"Running analysis for {CLUSTER_TYPE_ANALYSIS} clusters ({CLUST_INTER_MUT_MAX} cluster distance) with {SNP_NUM} SNPs and significance level {SIG}\")\n",
    "\n",
    "#cosmetics:\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "\n",
    "#create directory tree\n",
    "create_project_directory_tree()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data and Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#Create reference lookup table for all parental SNPs from parents\n",
    "parental_origin_db_df = createParentalOriginDF(\n",
    "    cfg[\"parents_path\"],\n",
    "    removeA3A_motif=False,\n",
    "    remove_problematic_positions=True,\n",
    "    remove_telomeres=True,\n",
    "    remove_all_repetitive_DNA=True,\n",
    "    parental_origin_db_df_path_save=\"outputs/all_parental_SNPs.tsv\")\n",
    "\n",
    "# Load the parental CLC SNPs calls and create a list of Sample objects\n",
    "samples_parental_SNPs = csvDataFrameImport(\n",
    "    directory=cfg[\"parental_SNPs_path\"], \n",
    "    kind=\"sample\", log=True, \n",
    "    format=\"csv\", \n",
    "    genotype_dict=genotype_dict)\n",
    "samples_parental_SNPs.sort()\n",
    "\n",
    "for i in samples_parental_SNPs:\n",
    "    i.qualitySNVFilter(diploid=diploid, params={\"min_frequency\": 30, \"min_coverage\": 8})\n",
    "\n",
    "# Perform heterozygosity and ploidy analysis. It modifies objects in samples_parental_SNPs list. Needs to be done before removing heterozygous calls.\n",
    "heterozygosity_ploidy_output = performHeterozygosityAndPloidyAnalysis(\n",
    "    samples_parental_SNPs, \n",
    "    show_details=False, \n",
    "    plot_coverage=False,\n",
    "    save_plot=False,\n",
    "    save_high_coverage_SNP_positions=True,\n",
    "    remove_aneuploid_from_high_coverage_SNP_positions=True,\n",
    "    parental_origin_db_df=parental_origin_db_df #if None, all SNVs, not just parental, will be shown\n",
    "    )\n",
    "\n",
    "for i in samples_parental_SNPs:\n",
    "    i.removeHeterozygousCalls()\n",
    "\n",
    "save_payload_to_pickle(samples_parental_SNPs, \"outputs/partial_pickles/samples_parental_SNPs_heterozygosity.pkl\")\n",
    "save_payload_to_pickle(parental_origin_db_df, \"outputs/partial_pickles/parental_origin_db_df.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#reload samples_parental_SNPs from pickle\n",
    "samples_parental_SNPs = load_payload_from_pickle(\"outputs/partial_pickles/samples_parental_SNPs_heterozygosity.pkl\")\n",
    "parental_origin_db_df = load_payload_from_pickle(\"outputs/partial_pickles/parental_origin_db_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) draw SNP density curves for parental SNPs\n",
    "\n",
    "lowDensityMap = loadDensityMap(lowDensity=True, max_distance=500)\n",
    "\n",
    "data_path = 'outputs/all_parental_SNPs.tsv'\n",
    "df = pd.read_csv(data_path, sep='\\t', header=0)\n",
    "df = df[df['Parent'] == \"parent_1\"]\n",
    "\n",
    "print(df['Chromosome'].value_counts())\n",
    "print(df['Zygosity'].value_counts())\n",
    "print(df['Parent'].value_counts())\n",
    "print(df[df['Zygosity'] != \"Homozygous\"])\n",
    "\n",
    "plot_chr_SNP_coverage_by_SNP_distance(\n",
    "    df, distance_max=5000, distace_step=5,\n",
    "    inverse=True,\n",
    "    by_chromosome=False,\n",
    "    save_path='outputs/SNP_density_poor.tsv',\n",
    "    fig_path='figures/other/SNP_density_poor.png')\n",
    "\n",
    "plot_chr_SNP_coverage_by_SNP_distance(\n",
    "    df, distance_max=5000, distace_step=5,\n",
    "    inverse=True,\n",
    "    by_chromosome=True,\n",
    "    save_path='outputs/SNP_density_poor.tsv',\n",
    "    fig_path='figures/other/SNP_density_poor_by_chr.png')\n",
    "\n",
    "plot_chr_SNP_coverage_by_SNP_distance(\n",
    "    df, distance_max=5000, distace_step=5,\n",
    "    inverse=False,\n",
    "    by_chromosome=False,\n",
    "    save_path='outputs/SNP_density.tsv',\n",
    "    fig_path='figures/other/SNP_dense.png')\n",
    "\n",
    "plot_chr_SNP_coverage_by_SNP_distance(\n",
    "    df, distance_max=5000, distace_step=5,\n",
    "    inverse=False,\n",
    "    by_chromosome=True,\n",
    "    save_path='outputs/SNP_density.tsv',\n",
    "    fig_path='figures/other/SNP_dense_by_chr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (required downstream) create recobination maps for each sample/object, and save them to file\n",
    "\n",
    "switches_list = createRecombinationMaps(\n",
    "    samples_parental_SNPs,\n",
    "    parental_origin_db_df,\n",
    "    df_chr,\n",
    "    starts,\n",
    "    draw_map = False, #set to False for faster processing\n",
    "    saveMap = False, #set to False for faster processing\n",
    "    min_SNPs_switch_support = SNP_NUM #=1 -> switch called with 1 supporting SNP, can be set to more however\n",
    ") \n",
    "    \n",
    "saveSwitchesToFile(switches_list, path=f\"outputs/all_switches_{SNP_NUM}snp.tsv\")\n",
    "save_payload_to_pickle(switches_list, f\"outputs/partial_pickles/switches_list_{SNP_NUM}snp.pkl\")\n",
    "save_payload_to_pickle(samples_parental_SNPs, f\"outputs/partial_pickles/samples_parental_SNPs_{SNP_NUM}snp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#Dealing with SNVs calls (A3A mutations)\n",
    "from mayo.settings import specific_genotypes_2, specific_genotypes_3, specific_genotypes_4\n",
    "\n",
    "samples_SNVs = csvDataFrameImport(\n",
    "    directory=cfg[\"SNVs_path\"],\n",
    "    kind=\"switches_overlap\",\n",
    "    log=True,\n",
    "    format=\"csv\",\n",
    "    genotype_dict=genotype_dict\n",
    "    )\n",
    "\n",
    "check_for_duplicate_sample_names(samples_SNVs)\n",
    "map_genotype_to_sample(samples_SNVs, genotype_dict)\n",
    "    \n",
    "samples_SNVs.sort()\n",
    "\n",
    "for i in samples_SNVs:\n",
    "    i.df = removeTelomereSNPs(i.df)\n",
    "    i.df = removeRepetitiveDNASNPs(i.df, repetitive_DNA_fasta_path=cfg[\"repetitive_regions_fasta_path\"])\n",
    "    i.qualitySNVFilter(\n",
    "        stringent=False, \n",
    "        diploid=diploid,\n",
    "        params={\"min_coverage\": 10, \"min_frequency\": 20})\n",
    "\n",
    "for sample in samples_SNVs:\n",
    "    sample.df[\"mutation\"] = sample.df[\"Chromosome\"].astype(str) + \"_\" + sample.df[\"Region\"].astype(str) + \"_\" + sample.df[\"Reference\"] + \"_\" + sample.df[\"Allele\"]\n",
    "\n",
    "df_all_mutations = createCombinedSNVsTable(samples_SNVs)\n",
    "df_all_mutations[\"genotype\"] = df_all_mutations[\"sample_name\"].apply(lambda x: genotype_dict[x] if x in genotype_dict.keys() else \"N/A\")\n",
    "print(\"Before filtering all mutations\", df_all_mutations.shape)\n",
    "\n",
    "#for random spores\n",
    "filterCommonMutations(\n",
    "    samples_SNVs, \n",
    "    max_duplicates = 10,\n",
    "    specific_genotypes = [\n",
    "        'ung1∆',\n",
    "        \"ung1∆NAT\",\n",
    "        \"ung1∆ EV\",\n",
    "        'ung1∆ premeiotic non-selected',\n",
    "        'ung1∆ non-selected',\n",
    "        'UNG1',\n",
    "        \"spo13∆\", \n",
    "        \"spo13∆spo11∆\",\n",
    "        \"spo13∆spo11∆ premeiotic\",\n",
    "        \"exo1-nd\",\n",
    "        \"pol32∆\",\n",
    "        \"exo1-ndpol32∆\",\n",
    "        \"sgs1∆C\",\n",
    "        \"exo1-ndsgs1∆C\"\n",
    "        ],\n",
    "    genotypes_dict=genotype_dict, \n",
    "    max_genotype_duplicates=3)\n",
    "\n",
    "#remove non-meiotic (premeiotic) mutations from tetrad/dyad data\n",
    "filterCommonMutations_sectors_premeiotic(\n",
    "    samples_SNVs, \n",
    "    specific_genotypes_2, \n",
    "    specific_genotypes_3, \n",
    "    specific_genotypes_4, \n",
    "    df_all_mutations, \n",
    "    genotype_dict,\n",
    "    minimum_count_within_genotype=0,\n",
    "    max_outside_genotype_duplicates=0)\n",
    "\n",
    "#compute and add JT clusters\n",
    "compute_and_add_JT_clusters(\n",
    "    samples_SNVs, \n",
    "    pvals_to_test = [0.01, 0.001, 0.0001, 0.00001, 0.000001], \n",
    "    max_distance_between_mutations = CLUST_INTER_MUT_MAX, \n",
    "    min_cluster_mutations = 3)\n",
    "\n",
    "showSpecificGenotypeClusters(\n",
    "    samples_SNVs,\n",
    "    specific_genotypes_2,\n",
    "    specific_genotypes_3,\n",
    "    specific_genotypes_4,\n",
    "    pval=0.0001)\n",
    "\n",
    "aggregateSectorsClusters(\n",
    "    df_clusters=pd.read_csv(f\"data/new_clusters/mutation_clusters/mutation_clusters_pval_{SIG}.tsv\", sep=\"\\t\", header=0, index_col=0),\n",
    "    specific_genotypes_2=specific_genotypes_2,\n",
    "    specific_genotypes_3=specific_genotypes_3,\n",
    "    specific_genotypes_4=specific_genotypes_4,\n",
    "    genotype_dict=genotype_dict,\n",
    "    remove_non_concordant=True,\n",
    "    cluster_outpath_individual=f\"outputs/sectors_cluster_table_with_post-meiotic_individuals_with_missing{SIG}.tsv\",\n",
    "    cluster_outpath_totals=f\"outputs/sectors_cluster_table_with_post-meiotic_totals_with_missing{SIG}.tsv\"\n",
    "    )\n",
    "\n",
    "save_payload_to_pickle(samples_SNVs, \"outputs/partial_pickles/samples_SNVs_with_post_meiotic.pkl\")\n",
    "save_payload_to_pickle(df_all_mutations, \"outputs/partial_pickles/df_all_mutations_with_post_meiotic.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt 2\n",
    "samples_SNVs = load_payload_from_pickle(\"outputs/partial_pickles/samples_SNVs_with_post_meiotic.pkl\")\n",
    "switches_list = load_payload_from_pickle(f\"outputs/partial_pickles/switches_list_{SNP_NUM}snp.pkl\")\n",
    "from mayo.settings import specific_genotypes_2, specific_genotypes_3, specific_genotypes_4\n",
    "\n",
    "#filter out mutations that happened after meiosis\n",
    "filterCommonMutations_sectors_postmeiotic(\n",
    "    samples_SNVs, \n",
    "    specific_genotypes_2, \n",
    "    specific_genotypes_3, \n",
    "    specific_genotypes_4, \n",
    "    df_all_mutations, \n",
    "    genotype_dict,\n",
    "    minimum_count_within_genotype_2=2,\n",
    "    minimum_count_within_genotype_3=3,\n",
    "    minimum_count_within_genotype_4=3,\n",
    "    max_outside_genotype_duplicates=0)\n",
    "\n",
    "# since some chr/calls can be diploid/triploid even, we shouldn't remove heterozygous calls or be too stringent with qualitySNVFilter\n",
    "for i in samples_SNVs:\n",
    "    i.qualitySNVFilter(\n",
    "        stringent=False, \n",
    "        diploid=diploid,\n",
    "        params={\"min_coverage\": 10, \"min_frequency\": 30})\n",
    "\n",
    "addSwitchesAndClustersToNormalSamples(samples_SNVs, switches_list, df_clusters_type=CLUSTER_TYPE_ANALYSIS, cluster_significance=SIG)\n",
    "\n",
    "# remove heterozygous calls in case of aneuploid chromosomes?\n",
    "for i in samples_SNVs:\n",
    "    if i.name in get_samples_with_genotype(\"ung1∆+ung1∆NAT+exo1-nd+pol32∆+ung1∆ non-selected+ung1∆ EV+UNG1+sgs1∆C+exo1-ndsgs1∆C\", genotype_dict): #\n",
    "        len_before = i.df.shape[0]\n",
    "        mask = ~i.df[\"Chromosome\"].isin(i.aneuploid_chromosomes + i.heterozygous_chromosomes)\n",
    "        i.df.loc[mask, 'Frequency'] = i.df.loc[mask, 'Frequency'].apply(lambda x: x if x >= 80 else None)\n",
    "        i.df.dropna(subset=['Frequency'], inplace=True)\n",
    "        len_after = i.df.shape[0]\n",
    "        logging.info(f\"{i.name}: Removed {len_before - len_after} heterozygous mutation calls from {i.name}. {len_after} calls left.\")\n",
    "        print(f\"{i.name}: Removed {len_before - len_after} heterozygous mutation calls from {i.name}. {len_after} calls left.\")\n",
    "\n",
    "#dealing with clusters\n",
    "compute_and_add_JT_clusters(\n",
    "    samples_SNVs, \n",
    "    pvals_to_test = [0.01, 0.001, 0.0001, 0.00001, 0.000001], \n",
    "    max_distance_between_mutations = CLUST_INTER_MUT_MAX, \n",
    "    min_cluster_mutations = 3)\n",
    "\n",
    "showSpecificGenotypeClusters(\n",
    "    samples_SNVs,\n",
    "    specific_genotypes_2,\n",
    "    specific_genotypes_3,\n",
    "    specific_genotypes_4,\n",
    "    pval=0.0001)\n",
    "\n",
    "aggregateSectorsClusters(\n",
    "    df_clusters=pd.read_csv(f\"data/new_clusters/mutation_clusters/mutation_clusters_pval_{SIG}.tsv\", sep=\"\\t\", header=0, index_col=0),\n",
    "    specific_genotypes_2=specific_genotypes_2,\n",
    "    specific_genotypes_3=specific_genotypes_3,\n",
    "    specific_genotypes_4=specific_genotypes_4,\n",
    "    genotype_dict=genotype_dict,\n",
    "    remove_non_concordant=True,\n",
    "    cluster_outpath_individual=f\"outputs/sectors_cluster_table_without_post-meiotic_individuals_with_missing{SIG}.tsv\",\n",
    "    cluster_outpath_totals=f\"outputs/sectors_cluster_table_without_post-meiotic_totals_with_missing{SIG}.tsv\")\n",
    "    \n",
    "save_payload_to_pickle(samples_SNVs, \"outputs/partial_pickles/samples_SNVs_without_post_meiotic.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "parental_origin_db_df = pd.read_csv(\"outputs/all_parental_SNPs.tsv\", sep=\"\\t\", header=0, index_col=0)\n",
    "samples_parental_SNPs = load_payload_from_pickle(f\"outputs/partial_pickles/samples_parental_SNPs_{SNP_NUM}snp.pkl\")\n",
    "samples_SNVs = load_payload_from_pickle(\"outputs/partial_pickles/samples_SNVs_without_post_meiotic.pkl\") #samples_SNVs_with_post_meiotic.pkl\n",
    "switches_list = load_payload_from_pickle(f\"outputs/partial_pickles/switches_list_{SNP_NUM}snp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) finds unreliable SNPs (based on coverage of pooled samples)\n",
    "findNonRepresentativeSNPs(\n",
    "    samples_parental_SNPs,\n",
    "    fig_name_freq_all = \"outputs/all_parental_snps_combined_frequency_count_distribution_all60_haploung1d.png\",\n",
    "    fig_name_freq_non_repr = \"outputs/all_parental_snps_combined_frequency_count_distribution_first57_haploung1d.png\",\n",
    "    non_representative_SNPs_out_path = \"outputs/unreliable_SNPs_freq_count.txt\") #output can be used to filter out imbalanced SNPs by adding them to problematic_positions.py\n",
    "\n",
    "# (optional) find imbalanced SNPs for the dataset (based on frequency of parental alleles in pooled progeny samples)\n",
    "df_imbalanced_all = find_imbalanced_snps(\n",
    "    genotype_dict=genotype_dict,\n",
    "    df_reference_path='outputs/all_parental_SNPs.tsv',\n",
    "    df_progeny_path='outputs/all_parental_snps_combined.csv',\n",
    "    genotype_list=[\n",
    "        \"ung1∆\",\n",
    "        \"UNG1\",\n",
    "        \"ung1∆ non-selected\",\n",
    "        \"exo1-nd\",\n",
    "        \"pol32∆\",\n",
    "        \"exo1-ndpol32∆\",\n",
    "        \"ung1∆NAT\",\n",
    "        \"ung1∆ EV\",\n",
    "        \"exo1-ndsgs1∆C\",\n",
    "        \"sgs1∆C\",\n",
    "        ],\n",
    "    by_genotype=False,\n",
    "    show=True,\n",
    "    save=True)\n",
    "\n",
    "df_imbalanced_all.to_csv(\"outputs/imbalanced_snps.csv\", sep=\"\\t\") #save to file #output can be used to filter out imbalanced SNPs by adding them to problematic_positions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove rtg samples from both samples_parental_SNPs and samples_SNVs\n",
    "from mayo.settings import rtg_list\n",
    "samples_parental_SNPs[:] = [i for i in samples_parental_SNPs if i.name not in rtg_list]\n",
    "samples_SNVs[:] = [i for i in samples_SNVs if i.name not in rtg_list]\n",
    "switches_list[:] = [i for i in switches_list if i.name not in rtg_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SIG = 0.0001 #0.01, 0.001, 0.0001, 0.00001, 0.000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# (required downstream) create a cluster table for each sample/object\n",
    "addSwitchesAndClustersToNormalSamples(samples_SNVs, switches_list, df_clusters_type=CLUSTER_TYPE_ANALYSIS, cluster_significance=SIG)\n",
    "find_GC_CO_from_switches(samples_SNVs, threshold_GC_max = 5000)\n",
    "calculate_GC_CO(samples_SNVs)\n",
    "calculate_scattered_SNPs(samples_SNVs)\n",
    "\n",
    "#find total amount of ssDNA from clusters (for quick overview)\n",
    "for p_val in [0.01, 0.001, 0.0001, 0.00001, 0.000001]:\n",
    "    showTotalssDNAinSamples_SNVs(\n",
    "        df_total_ssDNA = getTotalssDNAinSamples_SNVs(\n",
    "            samples_SNVs, \n",
    "            cluster_kind = \"JT\", \n",
    "            focus_set = get_samples_with_genotype(\"ung1∆+ung1∆NAT+exo1-nd+pol32∆+exo1-ndpol32∆+sgs1∆C+exo1-ndsgs1∆C\", genotype_dict)),\n",
    "        p_val=p_val)\n",
    "\n",
    "heterozygous_chr_counter, aneuploid_chr_counter = find_commonly_heterozygous_chromosomes(samples_parental_SNPs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) save all recombination events to a file\n",
    "df_all_rec_events = get_all_rec_events_df(\n",
    "    samples_SNVs, \n",
    "    genotype_dict, \n",
    "    query_genotypes=\"ung1∆+ung1∆NAT+UNG1+ung1∆ EV+ung1∆ non-selected+exo1-nd+pol32∆+exo1-ndpol32∆+sgs1∆C+exo1-ndsgs1∆C\",\n",
    "    skip_aneuploid_heterozygous_sample=False,\n",
    "    skip_aneuploid_heterozygous_chromosome=True)\n",
    "\n",
    "df_all_rec_events.rename(columns={\"Type\": \"Event\"}, inplace=True)\n",
    "df_all_rec_events.to_csv(f\"outputs/all_recombination_events_haploid_chromosomes_{SNP_NUM}snp.csv\", index=False, sep=\"\\t\", encoding='utf-16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(tests)\n",
    "from mayo.settings import sectors_wt, sectors_wt_reduced, sectors_spo13, sectors_spo13_reduced, sectors_spo13spo11, sectors_spo13spo11_reduced\n",
    "\n",
    "wt_counts = []\n",
    "spo13_counts = []\n",
    "spo13spo11_counts = []\n",
    "\n",
    "wt_counts_scattered = []\n",
    "spo13_counts_scattered = []\n",
    "spo13spo11_counts_scattered = []\n",
    "\n",
    "\n",
    "for sample in samples_SNVs:\n",
    "    if sample.name in sectors_wt_reduced:\n",
    "        sample_mutations = len(sample.df)\n",
    "        sample_scattered = len(sample.df_scattered)\n",
    "        wt_counts.append(sample_mutations)\n",
    "        wt_counts_scattered.append(sample_scattered)\n",
    "\n",
    "    elif sample.name in sectors_spo13_reduced:\n",
    "        sample_mutations = len(sample.df)\n",
    "        sample_scattered = len(sample.df_scattered)\n",
    "        spo13_counts.append(sample_mutations)\n",
    "        spo13_counts_scattered.append(sample_scattered)\n",
    "\n",
    "    elif sample.name in sectors_spo13spo11_reduced:\n",
    "        sample_mutations = len(sample.df)\n",
    "        sample_scattered = len(sample.df_scattered)\n",
    "        spo13spo11_counts.append(sample_mutations)\n",
    "        spo13spo11_counts_scattered.append(sample_scattered)\n",
    "\n",
    "\n",
    "#print average mutation counts\n",
    "print(f\"Average mutations in wt: {np.mean(wt_counts)}\")\n",
    "print(f\"Average mutations in spo13: {np.mean(spo13_counts)}\")\n",
    "print(f\"Average mutations in spo13spo11: {np.mean(spo13spo11_counts)}\")\n",
    "\n",
    "print(f\"Average scattered mutations in wt: {np.mean(wt_counts_scattered)}\")\n",
    "print(f\"Average scattered mutations in spo13: {np.mean(spo13_counts_scattered)}\")\n",
    "print(f\"Average scattered mutations in spo13spo11: {np.mean(spo13spo11_counts_scattered)}\")\n",
    "\n",
    "#compare by mann whitney u test each set of mutation counts\n",
    "from scipy.stats import mannwhitneyu\n",
    "print(\"Mann Whitney U test results for mutation counts between wt, spo13\")\n",
    "print(mannwhitneyu(wt_counts, spo13_counts))\n",
    "\n",
    "print(\"Mann Whitney U test results for mutation counts between wt, spo13spo11\")\n",
    "print(mannwhitneyu(wt_counts, spo13spo11_counts))\n",
    "\n",
    "print(\"Mann Whitney U test results for mutation counts between spo13, spo13spo11\")\n",
    "print(mannwhitneyu(spo13_counts, spo13spo11_counts))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) save SNVs to file\n",
    "saveClusteredSNVsToFile(samples_SNVs, f\"data/new_clusters/clustered_mutations/clustered_SNVs_{CLUSTER_TYPE_ANALYSIS}_{CLUST_INTER_MUT_MAX}_{SIG}.tsv\")\n",
    "saveScatteredSNVsToFile(samples_SNVs, f\"data/new_clusters/scattered_mutations/scattered_SNVs_{CLUSTER_TYPE_ANALYSIS}_{CLUST_INTER_MUT_MAX}_{SIG}.tsv\")\n",
    "df_all_mutations = createAllSNVsTable(samples_SNVs, genotypes_keep=None) #genotypes_keep=['ung1∆', \"ung1∆NAT\", 'ung1∆ non-selected']\n",
    "df_all_mutations.to_csv(f\"outputs/all_mutations.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all the data to pickle for cluster association null model simulations\n",
    "df_clusters=pd.read_csv(f\"data/new_clusters/mutation_clusters/mutation_clusters_pval_{SIG}.tsv\", sep=\"\\t\", header=0, index_col=0)\n",
    "save_payload_to_pickle([samples_SNVs, switches_list, df_clusters, chromosomes], f\"outputs/partial_pickles/saved_state_for_sim_{CLUSTER_TYPE_ANALYSIS}_{CLUST_INTER_MUT_MAX}_{SIG}_{SNP_NUM}snp.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Past Checkpoint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Basic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_ratios_list_pvals, clust_mut_vs_total_ssdna_list = calculateClusterStatistics(\n",
    "    samples_SNVs,\n",
    "    cluster_kind=CLUSTER_TYPE_ANALYSIS,\n",
    "    focus_set = get_samples_with_genotype(\"ung1∆\", genotype_dict)  #haploid_samples_ung1d\n",
    "    )\n",
    "\n",
    "df_ratios = pd.DataFrame(output_ratios_list_pvals, index=[\"0.01\", \"0.001\", \"0.0001\", \"0.00001\", \"0.000001\"]).T\n",
    "samples_count = len(df_ratios)\n",
    "plot_clust_scattered_ratio_kde(df_ratios, save_path=f\"figures/clustered_scattered_ratios_kde_{samples_count}_samples.png\", show=True)\n",
    "plot_clust_scattered_ratio_violin(df_ratios, save_path=f\"figures/clustered_scattered_ratios_violin_{samples_count}_samples.png\", show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !(optional) count the number of A3A signature SNPs in each sample\n",
    "countA3ASNPs_list(samples_SNVs)\n",
    "\n",
    "# (optional) time intensive; draw a context plot for combined samples SNVs\n",
    "genotypes_to_draw = [\n",
    "    \"ung1∆\",\n",
    "    # \"ung1∆NAT\",\n",
    "    # \"ung1∆ premeiotic non-selected\",\n",
    "    # \"UNG1\",\n",
    "    # None, #None will draw all samples\n",
    "    ]\n",
    "\n",
    "for genotype in genotypes_to_draw:\n",
    "    drawContextA3A(\n",
    "        samples_SNVs,\n",
    "        show=False,\n",
    "        save=True,\n",
    "        focus_set=get_samples_with_genotype(genotype, genotype_dict),\n",
    "        save_name_suffix=f\"{genotype}_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_GC_CO_distribution_by_genotype(\n",
    "    samples_SNVs, \n",
    "    query_genotypes = \"ung1∆+ung1∆NAT+exo1-nd+pol32∆+exo1-ndpol32∆\", #\n",
    "    save_name = \"distribution_haploid\",\n",
    "    show = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# (optional) conduct tests on distribution of mutations around recombination events\n",
    "\n",
    "A3A_mutations_proportion_df = get_proportion_of_A3A_mutations(samples_SNVs)\n",
    "\n",
    "averages = A3A_mutations_proportion_df.groupby(\"Genotype\")[\"Total mutations\"].mean()\n",
    "averages = averages[~averages.index.str.contains(\"sectors\")] #if genotype contains \"sectors\" remove it from averages list\n",
    "print(averages.head(50))\n",
    "\n",
    "plot_proportion_A3A_mutations(\n",
    "    A3A_mutations_proportion_df, \n",
    "    genotypes_include = [\n",
    "        'ung1∆ premeiotic non-selected',\n",
    "        'UNG1',\n",
    "        'ung1∆ EV',\n",
    "        'ung1∆ non-selected', \n",
    "        'ung1∆', \n",
    "        'ung1∆NAT', \n",
    "        'exo1-nd',\n",
    "        'pol32∆', \n",
    "        'exo1-ndpol32∆',\n",
    "        'sgs1∆C',\n",
    "        'exo1-ndsgs1∆C',\n",
    "        'spo13∆', \n",
    "        'spo13∆spo11∆', \n",
    "        ], \n",
    "    fig_size=(16, 6),\n",
    "    save_path = \"figures/A3A_fraction_boxplot_fig2.png\")\n",
    "\n",
    "\n",
    "window_size_norm = 10000\n",
    "\n",
    "genotype_list = [\"ung1∆\", \"pol32∆\", \"ung1∆NAT\",  \"exo1-nd\", \"exo1-ndpol32∆\", \"sgs1∆C\", \"exo1-ndsgs1∆C\"]\n",
    "\n",
    "meta_master_relative_GC_CO_df = get_rec_ev_relative_A3A_SNVs_and_plot(\n",
    "    samples_SNVs, \n",
    "    genotype_dict, \n",
    "    genotype_list=genotype_list,\n",
    "    mutation_type = \"all\",\n",
    "    window_size = window_size_norm)\n",
    "\n",
    "meta_master_relative_GC_CO_df_clustered = get_rec_ev_relative_A3A_SNVs_and_plot(\n",
    "    samples_SNVs, \n",
    "    genotype_dict, \n",
    "    genotype_list=genotype_list,\n",
    "    mutation_type = \"clustered\",\n",
    "    window_size = window_size_norm)\n",
    "\n",
    "meta_master_relative_GC_CO_df_scattered = get_rec_ev_relative_A3A_SNVs_and_plot(\n",
    "    samples_SNVs, \n",
    "    genotype_dict, \n",
    "    genotype_list=genotype_list,\n",
    "    mutation_type = \"scattered\",\n",
    "    window_size = window_size_norm)\n",
    "\n",
    "\n",
    "\n",
    "for index, item in enumerate([\n",
    "    [\"clustered\",   meta_master_relative_GC_CO_df_clustered],\n",
    "    [\"scattered\", meta_master_relative_GC_CO_df_scattered],\n",
    "    [\"all\", meta_master_relative_GC_CO_df]]):\n",
    "\n",
    "    name = item[0]\n",
    "    df = item[1]\n",
    "\n",
    "    print(f\"Plotting {name} mutations around recombination events...\")\n",
    "\n",
    "    print(df)\n",
    "\n",
    "    plot_normalized_rec_A3A(\n",
    "        df, \n",
    "        region = (-8, 8),\n",
    "        bins = 20,\n",
    "        poly_order = 1,\n",
    "        genotypes_include=genotype_list,\n",
    "        save_path=f\"figures/normalized_rec_A3A_8kb_16bins_linear_{name}.png\",\n",
    "        mutation_type=name)\n",
    "\n",
    "    plot_normalized_rec_A3A(\n",
    "        df, \n",
    "        region = (-12, 12), #in kb\n",
    "        bins = 24,\n",
    "        poly_order = 3,\n",
    "        genotypes_include=genotype_list,\n",
    "        save_path=f\"figures/normalized_rec_A3A_12kb_24bins_3rd_order_{name}.png\",\n",
    "        mutation_type=name)\n",
    "    \n",
    "    conduct_wilcoxon_signed_rank_test(df, 8, bins=32)\n",
    "    conduct_mann_whitney_U_test(df, 8, bins=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# (optional) below's output can be used for chi2 calculation of C->T and G->A balance of mutations around recombination events for different genotypes\n",
    "\n",
    "combined_meta_master_relative_GC_CO_df = pd.DataFrame()\n",
    "for mutation_type in [\"clustered\", \"scattered\", \"all\"]:\n",
    "    print(f\"Processing {mutation_type} mutations around recombination events...\")\n",
    "    meta_master_relative_GC_CO_df = get_rec_ev_relative_A3A_SNVs_mod(\n",
    "        samples_SNVs, \n",
    "        genotype_dict, \n",
    "        genotype_list = [\"ung1∆\", \"ung1∆NAT\", \"exo1-nd\", \"pol32∆\", \"exo1-ndpol32∆\", \"sgs1∆C\", \"exo1-ndsgs1∆C\"],\n",
    "        mutation_type= mutation_type,\n",
    "        window_size=10000)\n",
    "    \n",
    "    meta_master_relative_GC_CO_df[\"Cluster_pvalue\"] = SIG\n",
    "    meta_master_relative_GC_CO_df[\"Cluster_inter_mut_max\"] = CLUST_INTER_MUT_MAX\n",
    "    meta_master_relative_GC_CO_df.to_csv(f\"outputs/relative_mutations_GC_CO_{mutation_type}.csv\", sep=\"\\t\", index=False, encoding=\"utf-16\")\n",
    "\n",
    "    if mutation_type == \"all\":\n",
    "        mutation_type = \"clustered_and_scattered_(all)\"\n",
    "    meta_master_relative_GC_CO_df[\"mutation_type_set\"] = mutation_type\n",
    "    combined_meta_master_relative_GC_CO_df = pd.concat([combined_meta_master_relative_GC_CO_df, meta_master_relative_GC_CO_df], ignore_index=True)\n",
    "\n",
    "combined_meta_master_relative_GC_CO_df.to_csv(f\"outputs/relative_mutations_GC_CO_combined.csv\", sep=\"\\t\", index=False, encoding=\"utf-16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) plot location of switches (average positions between parental SNPs) on a chosen chromosome\n",
    "chromosome = 'ref|NC_001135|'\n",
    "showRecombinationHotspots(\n",
    "    switches_path=\"outputs/all_switches_1snp.tsv\", \n",
    "    chromosome=chromosome,\n",
    "    genotype_dict=genotype_dict,\n",
    "    genotype_list=[\"ung1∆\", \"ung1∆NAT\", \"pol32∆\", \"exo1-nd\", \"exo1-ndpol32∆\"],\n",
    "    show=True,\n",
    "    show_most_common=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) plot location of GC/CO events on chosen all chromosomes\n",
    "plot_rec_events_jointly(\n",
    "    df_all_rec_events = get_all_rec_events_df(\n",
    "        samples_SNVs, \n",
    "        genotype_dict, \n",
    "        query_genotypes=\"ung1∆+ung1∆NAT+exo1-nd+pol32∆+exo1-ndpol32∆\",\n",
    "        skip_aneuploid_heterozygous_sample=False,\n",
    "        skip_aneuploid_heterozygous_chromosome=True),\n",
    "    event_types = [\"GC\", \"CO\"],\n",
    "    save = True,\n",
    "    show = True,\n",
    "    output_path=f\"figures/rec_events/rec_events_across_all_chr_{SNP_NUM}.png\")\n",
    "\n",
    "# (optional) plot location of GC/CO events for all chromosomes, each separately\n",
    "plot_rec_events_for_all_chr(\n",
    "    df_all_rec_events = get_all_rec_events_df(\n",
    "        samples_SNVs, \n",
    "        genotype_dict, \n",
    "        query_genotypes=\"ung1∆+ung1∆NAT+exo1-nd+pol32∆+exo1-ndpol32∆\",\n",
    "        skip_aneuploid_heterozygous_sample=False,\n",
    "        skip_aneuploid_heterozygous_chromosome=True),\n",
    "    SNP_NUM = SNP_NUM,\n",
    "    event_types = [\"GC\", \"CO\"],\n",
    "    save = True,\n",
    "    show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from mayo.settings import sectors_wt, sectors_wt_reduced, sectors_spo13, sectors_spo13_reduced, sectors_spo13spo11, sectors_spo13spo11_reduced\n",
    "\n",
    "df_master_all, df_master_scattered, df_master_clusters, sample_size = createMasterSNVDataFrames(\n",
    "    samples_SNVs, \n",
    "    sample_names = sectors_spo13_reduced, # sectors_spo13spo11_reduced, sectors_wt_reduced, sectors_spo13_reduced\n",
    "    #sample_names = get_samples_with_genotype(\"ung1∆+pol32∆+exo1-nd+exo1-ndpol32∆+sgs1∆C+exo1-ndsgs1∆C\", genotype_dict),\n",
    "    just_heterozygous=False, \n",
    "    just_aneuploid=False)\n",
    "\n",
    "# draw map of all mutations among all samples in df_master_all/scattered/clusters\n",
    "drawSNPMap(TableSNP(df_master_all, \"master_all\"), df_chr, starts, showMap=True, saveMap=False, map_type=\"SNVs_A3A_no_switch\")\n",
    "drawSNPMap(TableSNP(df_master_scattered, \"master_scattered\"), df_chr, starts, showMap=True, saveMap=False, map_type=\"SNVs_A3A_no_switch\")\n",
    "drawSNPMap(TableSNP(df_master_clusters, \"master_clusters\"), df_chr, starts, showMap=True, saveMap=False, map_type=\"SNVs_A3A_no_switch\")\n",
    "\n",
    "# save df_master_all to pickle\n",
    "df_master_all.to_pickle(\"outputs/df_master_all.pkl\")\n",
    "df_master_clusters.to_pickle(\"outputs/df_master_clusters.pkl\")\n",
    "df_master_scattered.to_pickle(\"outputs/df_master_scattered.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transcription and mutagenesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from mayo.settings import non_essential_genes\n",
    "\n",
    "sample_set = \"spo13_tetrad\" # spo13spo11_tetrad, wt_tetrad, spo13_tetrad, random_spores\n",
    "query_positions = [\"Start\", \"End\"]\n",
    "\n",
    "df_mutations = df_master_all.copy()\n",
    "data_out = []\n",
    "\n",
    "for query_position in query_positions:\n",
    "\n",
    "    # number of samples that was used to collect the mutation data\n",
    "    sample_size_norm = sample_size\n",
    "    print(f\"Using {sample_size_norm} samples\")\n",
    "\n",
    "\n",
    "    ### ORF Coding\n",
    "    df_feature_mutations_master_coding, df_features = create_mutations_around_features_start_df(\n",
    "        df_mutations = df_mutations, \n",
    "        features_path = \"data/orf_coding.fasta\", #, \"data/orf_coding.fasta\", #\"data/other_features_genomic.fasta\", #,\n",
    "        query_position = query_position,\n",
    "        window_size = 1500,\n",
    "        just_non_essential_genes = non_essential_genes,\n",
    "        tss_and_tts_from_utrs = True,\n",
    "        UTR_data_path=\"data/yeastmine_results_2024-05-24T10-03-55.csv\"\n",
    "        )\n",
    "\n",
    "    df_nucleotide_freq = get_nucleotide_frequencies_around_feature(df_features, context_flank=1200, query_position=query_position)\n",
    "\n",
    "    smoothing_method = \"rolling\" # \"rolling\", \"savgol\"\n",
    "    rolling_window = 100\n",
    "    region_control = (600, 1200)\n",
    "    y_lim = None # None (0, 0.000075) (0, 0.001)\n",
    "\n",
    "    plot_mutations_around_feature(df_feature_mutations_master_coding, title=f\"Mutations around Feature {query_position} (protein coding)\", window_size=1200)\n",
    "    plot_mutations_around_feature(df_feature_mutations_master_coding, title=f\"Mutations around Feature {query_position} (protein coding)\", window_size=500)\n",
    "    plot_A3A_motifs_relative_to_position(countA3A_motifs_relative_to_position(df_features, context_flank=200, query_position=query_position), suffix=f\"orf_coding_200_{query_position}_{sample_set}\")\n",
    "    df_features_mod = countA3A_motifs_relative_to_position(df_features, context_flank=1200, query_position=query_position)\n",
    "    plot_A3A_motifs_relative_to_position(df_features_mod, suffix=f\"orf_coding_1200_{query_position}_{sample_set}\")\n",
    "    df_norm = normalize_mutations_around_feature(df_feature_mutations_master_coding, df_features_mod, feature_range=(-1200, 1200), sample_size_norm=sample_size_norm, feature_count_norm=4410)\n",
    "    plot_normalized_mutations_around_feature(df_norm, suffix=f\"orf_coding_1200_{query_position}_{sample_set}\", smoothing_method=smoothing_method, rolling_window=rolling_window, y_lim=y_lim, include_scatter=False)\n",
    "    plot_normalized_mutations_around_feature(df_norm[(df_norm['Region'] > -500) & (df_norm['Region'] < 500)], suffix=f\"orf_coding_500_{query_position}_{sample_set}\", smoothing_method=smoothing_method, rolling_window=rolling_window, y_lim=y_lim, include_scatter=False)\n",
    "\n",
    "    result_list_pk = []\n",
    "    result_list_pk.append(conduct_mann_u_for_normalized_mutations_around_feature(df_norm, region_test=(-25, 25), region_control=(-1200, -900)))\n",
    "    result_list_pk.append(conduct_mann_u_for_normalized_mutations_around_feature(df_norm, region_test=(-25, 25), region_control=region_control))\n",
    "    result_list_pk.append(conduct_mann_u_for_normalized_mutations_around_feature(df_norm, region_test=(-50, 50), region_control=region_control))\n",
    "    result_list_pk.append(conduct_mann_u_for_normalized_mutations_around_feature(df_norm, region_test=(-100, 100), region_control=region_control))\n",
    "    result_list_pk.append(conduct_mann_u_for_normalized_mutations_around_feature(df_norm, region_test=(-150, 150), region_control=region_control))\n",
    "\n",
    "    for result_set in result_list_pk:\n",
    "        for result in result_set:\n",
    "            data_out.append({\n",
    "                \"Feature Type\": \"Protein coding\",\n",
    "                \"Spectra\": result[0],\n",
    "                \"Position\": query_position,\n",
    "                \"Test\": result[1],\n",
    "                \"Control\": result[2],\n",
    "                \"p-value\": result[3],\n",
    "                \"Mean Test\": result[4],\n",
    "                \"Mean Control\": result[5],\n",
    "                \"Test/Control Ratio\": result[4] / result[5]\n",
    "            })\n",
    "\n",
    "    ### RNA Coding\n",
    "    df_feature_mutations_master_rna, df_features_rna = create_mutations_around_features_start_df(\n",
    "        df_mutations = df_mutations, \n",
    "        features_path = \"data/rna_coding.fasta\",\n",
    "        query_position = query_position,\n",
    "        window_size = 1500,\n",
    "        just_tRNA_genes = True)\n",
    "\n",
    "    y_lim = None # (0, 0.002) (0, .6)\n",
    "\n",
    "    plot_mutations_around_feature(df_feature_mutations_master_rna, title=f\"Mutations around Feature {query_position} (rna coding)\", window_size=1200)\n",
    "    plot_mutations_around_feature(df_feature_mutations_master_rna, title=f\"Mutations around Feature {query_position} (rna coding)\", window_size=500)\n",
    "    plot_A3A_motifs_relative_to_position(countA3A_motifs_relative_to_position(df_features_rna, context_flank=200, query_position=query_position), suffix=f\"rna_coding_200_{query_position}_{sample_set}\")\n",
    "    df_features_mod_rna = countA3A_motifs_relative_to_position(df_features_rna, context_flank=1200, query_position=query_position)\n",
    "    plot_A3A_motifs_relative_to_position(df_features_mod_rna, suffix=f\"rna_coding_1200_{query_position}_{sample_set}\")\n",
    "    df_norm = normalize_mutations_around_feature(df_feature_mutations_master_rna, df_features_mod_rna, feature_range=(-1200, 1200), sample_size_norm=sample_size_norm, feature_count_norm=275)\n",
    "    plot_normalized_mutations_around_feature(df_norm, suffix=f\"rna_coding_1200_{query_position}_{sample_set}\", smoothing_method=smoothing_method, rolling_window=rolling_window, y_lim=y_lim, include_scatter=False)\n",
    "    plot_normalized_mutations_around_feature(df_norm[(df_norm['Region'] > -500) & (df_norm['Region'] < 500)], suffix=f\"rna_coding_500_{query_position}_{sample_set}\", smoothing_method=smoothing_method, rolling_window=rolling_window, y_lim=y_lim, include_scatter=False)\n",
    "\n",
    "    result_list_trna = []\n",
    "    \n",
    "    result_list_trna.append(conduct_mann_u_for_normalized_mutations_around_feature(df_norm, region_test=(0, 100), region_control=region_control))\n",
    "    result_list_trna.append(conduct_mann_u_for_normalized_mutations_around_feature(df_norm, region_test=(0, 100), region_control=(-1200, -900)))\n",
    "\n",
    "    for result_set in result_list_trna:\n",
    "        for result in result_set:\n",
    "            data_out.append({\n",
    "                \"Feature Type\": \"tRNA\",\n",
    "                \"Spectra\": result[0],\n",
    "                \"Position\": query_position,\n",
    "                \"Test\": result[1],\n",
    "                \"Control\": result[2],\n",
    "                \"p-value\": result[3],\n",
    "                \"Mean Test\": result[4],\n",
    "                \"Mean Control\": result[5],\n",
    "                \"Test/Control Ratio\": result[4] / result[5]\n",
    "            })\n",
    "\n",
    "output_file = f\"outputs/mann_u_results_mut_rates_around_features_{sample_set}.csv\"\n",
    "\n",
    "# Create a DataFrame from the collected data\n",
    "df_out = pd.DataFrame(data_out)\n",
    "df_out[\"sample_set\"] = sample_set\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_out.to_csv(output_file, index=False, encoding=\"utf-16\", sep=\"\\t\")\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the df_nucleotide_freq dataframe where the x-axis is the index and the y-axis is the frequency of each nucleotide\n",
    "plot_nucleotide_frequencies_around_feature(df_nucleotide_freq, save_name=None, show=True, plot_limits=(-500, 500))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_filter = df_feature_mutations_master_coding[(df_feature_mutations_master_coding['Region'] > -75) & (df_feature_mutations_master_coding['Region'] < 75)]\n",
    "\n",
    "df_filter.Feature.value_counts().to_csv(\"feature_mutations_counts___sectors.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open table S1 from https://doi.org/10.1093/nar/gkac640\n",
    "\n",
    "df_features_summary = pd.read_csv(\"df_features_summary.csv\", sep=\",\", header=0)\n",
    "df_table_S1 = pd.read_csv(\"data/Table_S1.csv\", sep=\",\", header=0)\n",
    "\n",
    "keep_cols = [\n",
    "    'Gene id', \n",
    "    'Gene name', \n",
    "    'Contig',\n",
    "    'Start', \n",
    "    'End', \n",
    "    'Chromosome S288C', \n",
    "    'Start S288C', \n",
    "    'End S288C',\n",
    "    'Gene length',\n",
    "\n",
    "    \"WT 0h R1 (normalized and divided by gene length in kb)\",\n",
    "    \"WT 0h R2 (normalized and divided by gene length in kb)\",\n",
    "    \"WT 0h R3  (normalized and divided by gene length in kb)\",\n",
    "\n",
    "    \"WT 2h R1 (normalized and divided by gene length in kb)\",\n",
    "    \"WT 2h R2 (normalized and divided by gene length in kb)\",\n",
    "    \"WT 2h R3  (normalized and divided by gene length in kb)\",\n",
    "\n",
    "    \"WT 3h R1 (normalized and divided by gene length in kb)\",\n",
    "    \"WT 3h R2 (normalized and divided by gene length in kb)\",\n",
    "    \"WT 3h R3  (normalized and divided by gene length in kb)\",\n",
    "\n",
    "    \"WT 5h R1 (normalized and divided by gene length in kb)\",\n",
    "    \"WT 5h R2 (normalized and divided by gene length in kb)\",\n",
    "    \"WT 5h R3  (normalized and divided by gene length in kb)\",\n",
    "\n",
    "    \"WT 6h R1 (normalized and divided by gene length in kb)\",\n",
    "    \"WT 6h R2 (normalized and divided by gene length in kb)\",\n",
    "    \"WT 6h R3  (normalized and divided by gene length in kb)\",\n",
    "\n",
    "    'WT 7h R1 (normalized and divided by gene length in kb)',\n",
    "    'WT 7h R2 (normalized and divided by gene length in kb)',\n",
    "    'WT 7h R3  (normalized and divided by gene length in kb)',\n",
    "\n",
    "    'WT 9h R1 (normalized and divided by gene length in kb)',\n",
    "    'WT 9h R2 (normalized and divided by gene length in kb)',\n",
    "    'WT 9h R3  (normalized and divided by gene length in kb)'\n",
    "    ]\n",
    "\n",
    "df_table_S1 = df_table_S1[keep_cols]\n",
    "df_table_S1 = df_table_S1.rename(columns={\n",
    "    \"Gene id\": \"feature_name\",\n",
    "    \"WT 0h R1 (normalized and divided by gene length in kb)\": \"WT_0h_R1\",\n",
    "    \"WT 0h R2 (normalized and divided by gene length in kb)\": \"WT_0h_R2\",\n",
    "    \"WT 0h R3  (normalized and divided by gene length in kb)\":\"WT_0h_R3\",\n",
    "\n",
    "    \"WT 2h R1 (normalized and divided by gene length in kb)\": \"WT_2h_R1\",\n",
    "    \"WT 2h R2 (normalized and divided by gene length in kb)\": \"WT_2h_R2\",\n",
    "    \"WT 2h R3  (normalized and divided by gene length in kb)\":\"WT_2h_R3\",\n",
    "\n",
    "    \"WT 3h R1 (normalized and divided by gene length in kb)\": \"WT_3h_R1\",\n",
    "    \"WT 3h R2 (normalized and divided by gene length in kb)\": \"WT_3h_R2\",\n",
    "    \"WT 3h R3  (normalized and divided by gene length in kb)\":\"WT_3h_R3\",\n",
    "\n",
    "    \"WT 5h R1 (normalized and divided by gene length in kb)\": \"WT_5h_R1\",\n",
    "    \"WT 5h R2 (normalized and divided by gene length in kb)\": \"WT_5h_R2\",\n",
    "    \"WT 5h R3  (normalized and divided by gene length in kb)\":\"WT_5h_R3\",\n",
    "\n",
    "    \"WT 6h R1 (normalized and divided by gene length in kb)\": \"WT_6h_R1\",\n",
    "    \"WT 6h R2 (normalized and divided by gene length in kb)\": \"WT_6h_R2\",\n",
    "    \"WT 6h R3  (normalized and divided by gene length in kb)\":\"WT_6h_R3\",\n",
    "\n",
    "    'WT 7h R1 (normalized and divided by gene length in kb)': \"WT_7h_R1\",\n",
    "    'WT 7h R2 (normalized and divided by gene length in kb)': \"WT_7h_R2\",\n",
    "    'WT 7h R3  (normalized and divided by gene length in kb)':\"WT_7h_R3\",\n",
    "\n",
    "    'WT 9h R1 (normalized and divided by gene length in kb)': \"WT_9h_R1\",\n",
    "    'WT 9h R2 (normalized and divided by gene length in kb)': \"WT_9h_R2\",\n",
    "    'WT 9h R3  (normalized and divided by gene length in kb)':\"WT_9h_R3\",\n",
    "    \n",
    "    })\n",
    "\n",
    "df_features_summary_merge = df_features_summary.copy()\n",
    "df_features_summary_merge = df_features_summary_merge[[\"feature_name\", \"feature_count\"]]\n",
    "\n",
    "df_features_summary_merge = df_features_summary_merge.merge(df_table_S1, on=\"feature_name\", how=\"left\")\n",
    "\n",
    "df_mutated_feature = df_features_summary_merge[df_features_summary_merge[\"feature_count\"] > 5].dropna()\n",
    "df_unaltererd_feature = df_features_summary_merge[df_features_summary_merge[\"feature_count\"] == 0].dropna()\n",
    "\n",
    "#compare the 'WT 9h R1 (normalized and divided by gene length in kb)' column between the mutated and unaltered features\n",
    "from scipy.stats import mannwhitneyu\n",
    "columns = [\n",
    "    \"WT_0h_R1\",\n",
    "    \"WT_0h_R2\",\n",
    "    \"WT_0h_R3\",\n",
    "    \"WT_2h_R1\",\n",
    "    \"WT_2h_R2\",\n",
    "    \"WT_2h_R3\",\n",
    "    \"WT_3h_R1\",\n",
    "    \"WT_3h_R2\",\n",
    "    \"WT_3h_R3\",\n",
    "    \"WT_5h_R1\",\n",
    "    \"WT_5h_R2\",\n",
    "    \"WT_5h_R3\",\n",
    "    \"WT_6h_R1\",\n",
    "    \"WT_6h_R2\",\n",
    "    \"WT_6h_R3\",\n",
    "    \"WT_7h_R1\",\n",
    "    \"WT_7h_R2\",\n",
    "    \"WT_7h_R3\",\n",
    "    \"WT_9h_R1\",\n",
    "    \"WT_9h_R2\",\n",
    "    \"WT_9h_R3\"\n",
    "    ]\n",
    "\n",
    "df_heatmap = pd.DataFrame()\n",
    "\n",
    "for column in columns:\n",
    "    fold_change = df_mutated_feature[column].mean() / df_unaltererd_feature[column].mean()\n",
    "    mannwhitneyu_stat, pval = mannwhitneyu(df_mutated_feature[column], df_unaltererd_feature[column])\n",
    "    genotype, timepoint, replicate = column.split(\"_\")\n",
    "    new_data = {\n",
    "        \"column\": column, \n",
    "        \"fold_change\": fold_change, \n",
    "        \"pval\": pval,\n",
    "        \"genotype\": genotype,\n",
    "        \"timepoint\": timepoint,\n",
    "        \"replicate\": replicate\n",
    "        }\n",
    "    df_heatmap = pd.concat([df_heatmap, pd.DataFrame([new_data])]).reset_index(drop=True)\n",
    "    \n",
    "    # plt.figure(figsize=(5, 5))\n",
    "    # df_plot = df_mutated_feature.copy()\n",
    "    #groupby the feature_count and take the mean of the column\n",
    "    #df_plot = df_plot.groupby(\"feature_count\")[column].mean().reset_index()\n",
    "    #sns.regplot(data=df_plot, x=\"feature_count\", y=column, scatter_kws={\"s\": 20})\n",
    "\n",
    "#plot the heatmap where y-axis is replicate, x-axis is timepoint and the color is the fold change\n",
    "\n",
    "df_heatmap = df_heatmap.pivot(index=\"replicate\", columns=\"timepoint\", values=\"fold_change\") #values=\"pval\", \"fold_change\"\n",
    "sns.set_context(\"talk\")\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "#make annotations small\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "#sns.heatmap(df_heatmap, annot=True, cmap=sns.light_palette(\"seagreen\", as_cmap=True, reverse=True), annot_kws={\"size\":12}, norm=LogNorm())\n",
    "sns.heatmap(df_heatmap, annot=True, cmap=\"coolwarm\", center=1) \n",
    "# plt.title(\"Fold change in expression levels between genes\\n with high mutation rate promoters vs other promoters\", fontweight='bold')\n",
    "#rename the axes\n",
    "plt.xlabel(\"Timepoint\", fontweight='bold')\n",
    "plt.ylabel(\"Replicate\", fontweight='bold')\n",
    "plt.tight_layout()\n",
    "#save the figure\n",
    "plt.savefig(\"fold_change_heatmap.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(df_heatmap)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) Draw a map of clusters and switches ticks with distinct colors for A3A C>T and A3A G>A mutations\n",
    "for i in samples_SNVs:\n",
    "    drawSNPMap(i, df_chr, starts, saveMap=False, showMap=True, map_type=f\"SNVs_A3A_cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (required downstream) execute only once!\n",
    "createDatasetNullHypothesis(switches_list, chromosomes) # this is throwing an error in null hypothesis if executed here, but is needed for overlapClustersWithSwitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (required downstream) find clusters that overlap with recombination events (switches) within a window of 5000 bp, and draw a map of them\n",
    "for SIG in [0.01, 0.001, 0.00001, 0.000001, 0.0001]:\n",
    "\n",
    "    df_chr = pd.DataFrame(chromosomes, columns=[\"chromosome\", \"end_position\"])\n",
    "    master_counted_clusters_df = overlapClustersWithSwitches(\n",
    "        samples_SNVs = samples_SNVs,\n",
    "        window_size = 5000,\n",
    "        switches_list = switches_list,\n",
    "        df_chr = df_chr,\n",
    "        drawMap = False,\n",
    "        df_clusters_type = CLUSTER_TYPE_ANALYSIS,\n",
    "        cluster_significance = SIG)\n",
    "\n",
    "    #save the dataframe to a csv file\n",
    "\n",
    "    master_counted_clusters_df.to_csv(\n",
    "        f'outputs/associations/{CLUSTER_TYPE_ANALYSIS}/{SNP_NUM}snp/master_clusters_association_{SIG}_{SNP_NUM}snp_{CLUST_INTER_MUT_MAX}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) Draw a map of all mutations and switches ticks with distinct colors for A3A C>T and A3A G>A mutations\n",
    "for i in samples_SNVs:\n",
    "    drawSNPMap(i, df_chr, starts, saveMap=False, showMap=True, map_type=f\"SNVs_clustered\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_names = get_samples_with_genotype(\"ung1∆+ung1∆NAT+exo1-nd+exo1-ndpol32∆+pol32∆+sgs1∆C+exo1-ndsgs1∆C\", genotype_dict)\n",
    "homozygous_samples = []\n",
    "for i in samples_SNVs:\n",
    "    if i.name in sample_names:\n",
    "        if i.heterozygous == False:\n",
    "            homozygous_samples.append(i.name)\n",
    "print(f\"there are {len(homozygous_samples)} homozygous samples\")\n",
    "print(homozygous_samples)\n",
    "\n",
    "df_gaps = getHaplotypeLengthDistributionVsExpected(\n",
    "    switches_list, \n",
    "    filter_set=homozygous_samples,\n",
    "    inverse=False,\n",
    "    random_trials=100,\n",
    "    fraction_increment=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotHaplotypeLengthDistributionVsExpected(\n",
    "    df_gaps,\n",
    "    show=True, \n",
    "    figsize=(8, 5),\n",
    "    yticks=np.arange(0, 0.51, 0.1),\n",
    "    save_path=\"figures/haplotype_length_distribution_vs_expected_100_1snp.png\")\n",
    "\n",
    "df_blocks = getHaplotypeBlockLengths(switches_list=switches_list, filter_set=homozygous_samples, random=False, inverse=False)\n",
    "df_blocks[\"Distance_kb\"] = df_blocks[\"Distance\"]/1000\n",
    "df_blocks_mod = df_blocks[df_blocks[\"Distance_kb\"] <= 10]\n",
    "\n",
    "plotHaplotypeLengthDistributionHist(\n",
    "    df_blocks=df_blocks_mod,\n",
    "    figsize=(10, 5),\n",
    "    xticks=np.arange(0, 10, 1),\n",
    "    show=True,\n",
    "    save_path=f\"figures/haplotype_block_length_distribution_{SNP_NUM}snp_50kb.png\")\n",
    "\n",
    "df = smoothen_derive_col_data(df_gaps, \"Fraction_real\", window_length = 20, derivative = 1)\n",
    "\n",
    "plot_col_series(\n",
    "    df=df, \n",
    "    col_name=\"Fraction_real\", \n",
    "    x_col=\"Distance_kb\",\n",
    "    show=True, \n",
    "    show_smoothed_derived=True,\n",
    "    show_original=False,\n",
    "    title=\"Rate of change in cumulative fraction of haplotype block lengths\",\n",
    "    save_path=f\"figures/haplotype_block_rate_{SNP_NUM}snp_50kb.png\",\n",
    "    label=\"Rate\",\n",
    "    x_label=\"Haplotype block length (kb)\",\n",
    "    y_label=\"Rate of haplotype block fraction gain\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_name_clusters_null=\"proximal_clusters_125_1snp_full_combined.csv\"\n",
    "save_path_fig=\"figures/null_hypothesis/proximal_clusters_10k_haploid_1snp.png\"\n",
    "drawNullHypothesisSimulationResults(save_file_name_clusters_null, show=True, as_percent=True, bootstrap=False, other_clusters=False, save_path=save_path_fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#before starting, save the state of samples_SNVs, switches_list, and chromosomes\n",
    "payload_path = f\"outputs\\partial_pickles\\samples_parental_SNPs_{CLUSTER_TYPE_ANALYSIS}_{SIG}_{SNP_NUM}snp.pkl\"\n",
    "save_payload_to_pickle([samples_SNVs, switches_list, chromosomes], payload_path)\n",
    "\n",
    "samples_SNVs, switches_list, chromosomes = load_payload_from_pickle(payload_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#draw cluster_length distribution\n",
    "from mayo.settings import rtg_list\n",
    "\n",
    "df_clusters = pd.read_csv(\"data/new_clusters/mutation_clusters/mutation_clusters_pval_0.0001.tsv\", sep=\"\\t\")\n",
    "sample_names = get_samples_with_genotype(\"ung1∆+ung1∆NAT+ung1∆ non-selected\", genotype_dict) #+exo1-nd+pol32∆+exo1-ndpol32∆, ung1∆+ung1∆NAT+ung1∆ non-selected\n",
    "df_clusters = df_clusters[df_clusters[\"sample\"].isin(sample_names)]\n",
    "df_clusters[\"genotype\"] = df_clusters[\"sample\"].map(genotype_dict)\n",
    "df_clusters = df_clusters[~df_clusters[\"sample\"].isin(rtg_list)]\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "#plot distributions of cluster lengths\n",
    "df_clusters = df_clusters.rename(columns={\"genotype\": \"Genotype\"})\n",
    "#italicize the genotype names\n",
    "df_clusters[\"Genotype\"] = df_clusters[\"Genotype\"].apply(lambda x: f\"${x}$\")\n",
    "sns.set_context(\"poster\")\n",
    "plt.figure(figsize=(20, 5))\n",
    "palette = {\n",
    "    \"$ung1∆$\": \"tab:blue\",\n",
    "    \"$ung1∆NAT$\": \"tab:purple\",\n",
    "    \"$ung1∆ non-selected$\": \"tab:green\"\n",
    "}\n",
    "sns.histplot(data=df_clusters, x=\"Length\", bins=250, hue=\"Genotype\", palette=palette, fill=True, multiple=\"stack\", alpha=0.85)\n",
    "plt.xlabel(\"Cluster length (bp)\", fontweight='bold')\n",
    "plt.ylabel(\"Number of clusters\", fontweight='bold')\n",
    "plt.title(\"Distribution of cluster lengths\", fontweight='bold')\n",
    "\n",
    "#save the figure\n",
    "plt.savefig(\"figures/cluster_length_distribution.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawSNPMap(\n",
    "        SampleTable_Object,\n",
    "        df_chr_lengths: pd.DataFrame,\n",
    "        chr_starts_df: pd.DataFrame,\n",
    "        saveMap: bool = True,\n",
    "        map_type: str = \"switches\",\n",
    "        showMap: bool = False,\n",
    "        save_name_suffix: str = \"\",\n",
    "        cluster_kind: str | None = None\n",
    "        ) -> None:\n",
    "    '''Draws a SNP map for a given SampleTable object and saves it as a PNG file.\n",
    "\n",
    "    Args:\n",
    "        SampleTable_Object (SampleTable): A SampleTable object representing the \n",
    "            sample to be plotted.\n",
    "        df_chr_lengths (pandas.DataFrame): A pandas DataFrame containing the \n",
    "            lengths of each chromosome.\n",
    "        chr_starts_df (pandas.DataFrame): A pandas DataFrame containing the \n",
    "            start positions of each chromosome.\n",
    "        saveMap (bool, optional): A boolean indicating whether to save the map \n",
    "            as a PNG file. Defaults to True.\n",
    "        map_type (str, optional): A string indicating the type of SNP map to \n",
    "            draw. Possible values are \"switches\", \"SNPs\", \"SNVs_A3A_cluster\", and \"SNVs_A3A_all\"\n",
    "            Defaults to \"switches\".\n",
    "        showMap (bool, optional): A boolean indicating whether to show the map \n",
    "            in a window. Defaults to False.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    '''\n",
    "\n",
    "    # style with ticks\n",
    "    sns.set_style(\"ticks\")\n",
    "    sns.set_context(\"notebook\", font_scale=1.5, rc={\"lines.linewidth\": 2.5})\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    title = f\"{SampleTable_Object.name}\" #{round(SampleTable_Object.percent,3)}\n",
    "    \n",
    "    df_chr_lengths = renameChrToRoman(df_chr_lengths, \"chromosome\")\n",
    "    #use #E6E6E6 for gray color\n",
    "    df_chr_lengths.plot(kind='barh',legend=False, ax=ax, x=\"chromosome\", y=\"end_position\", fontsize=15, figsize=(20,6), edgecolor=\"black\", linewidth=1, color=\"#E6E6E6\" , zorder=2, title=title, label=\"Position\")\n",
    "\n",
    "    #To rename legend elements, change plot markers/colors, modify here\n",
    "    label_dict = {\"REF\": \"Reference Allele\"}\n",
    "    \n",
    "    if map_type==\"switches\":\n",
    "        palette = {\"parent_1\": \"tab:green\", \"parent_2\": \"tab:red\"}\n",
    "        markers = {\"parent_1\": \"|\", \"parent_2\": \"|\"}\n",
    "\n",
    "        pd_df = SampleTable_Object.output_df.copy()\n",
    "        pd_df = pd.concat([pd_df, chr_starts_df], ignore_index=True)\n",
    "        pd_df = renameChrToRoman(pd_df, \"Chromosome\")\n",
    "        sns.scatterplot(ax=ax, data=pd_df, x=\"Region\", y=\"Chromosome\", hue=\"Parent\", palette=palette, style=\"Parent\", markers=markers, s=120, alpha=0.5,zorder=3, linewidth=1.5)\n",
    "\n",
    "    #renamed from SNPs to SNVs\n",
    "    elif map_type==\"SNVs\":\n",
    "        pd_df = SampleTable_Object.df.copy()\n",
    "        pd_df = pd.concat([pd_df, chr_starts_df], ignore_index=True)\n",
    "        pd_df = renameChrToRoman(pd_df, \"Chromosome\")\n",
    "        sns.scatterplot(ax=ax, data=pd_df, x=\"Region\", y=\"Chromosome\", marker=\"|\", s=120, alpha=0.5,zorder=3, linewidth=1.5)\n",
    "    \n",
    "    elif map_type==\"SNVs_A3A_no_switch\":\n",
    "        pd_df = SampleTable_Object.df.copy()\n",
    "        pd_df = pd_df[(((pd_df[\"Reference\"] == \"C\") & (pd_df[\"Allele\"] == \"T\")) | ((pd_df[\"Reference\"] == \"G\") & (pd_df[\"Allele\"] == \"A\")))]\n",
    "        pd_df = pd.concat([pd_df, chr_starts_df], ignore_index=True).sort_values(by=[\"Chromosome\", \"Region\"])\n",
    "        pd_df = renameChrToRoman(pd_df, \"Chromosome\")\n",
    "        palette = {\"C\": \"tab:blue\", \"G\": \"tab:red\", 'NaN': \"tab:gray\", \"T\": \"tab:gray\", \"A\": \"tab:gray\"}\n",
    "        sns.scatterplot(ax=ax, data=pd_df, x=\"Region\", y=\"Chromosome\", marker=\"|\", s=120, alpha=1, zorder=3, linewidth=1.5, hue=\"Reference\", palette=palette)\n",
    "\n",
    "    elif map_type==\"SNVs_A3A_cluster\":\n",
    "        pd_df = SampleTable_Object.df_SNPs.copy()\n",
    "        pd_df = pd_df[(((pd_df[\"Reference\"] == \"C\") & (pd_df[\"Allele\"] == \"T\")) | ((pd_df[\"Reference\"] == \"G\") & (pd_df[\"Allele\"] == \"A\")))]\n",
    "        pd_df = pd.concat([pd_df, chr_starts_df], ignore_index=True).sort_values(by=[\"Chromosome\", \"Region\"])\n",
    "        pd_df = renameChrToRoman(pd_df, \"Chromosome\")\n",
    "        palette = {\"C\": \"tab:blue\", \"G\": \"tab:red\", 'NaN': \"tab:gray\", \"T\": \"tab:gray\", \"A\": \"tab:gray\"}\n",
    "        sns.scatterplot(ax=ax, data=pd_df, x=\"Region\", y=\"Chromosome\", marker=\"|\", s=120, alpha=1, zorder=3, linewidth=1.5, hue=\"Reference\", palette=palette)\n",
    "\n",
    "        switches_df = SampleTable_Object.switchesTable.copy()\n",
    "        switches_df = switches_df[switches_df[\"Chromosome\"] != \"ref|NC_001224|\"]\n",
    "        switches_df = pd.concat([switches_df, starts_switches], ignore_index=True)\n",
    "        switches_df = renameChrToRoman(switches_df, \"Chromosome\")\n",
    "        sns.scatterplot(ax=ax,data=switches_df, x=\"Switch_Center\", y=\"Chromosome\", color=\"black\", marker=2, s=120, zorder=0, linewidth=2.5, alpha=0.8)\n",
    "\n",
    "    elif map_type==\"SNVs_A3A\":\n",
    "        pd_df = SampleTable_Object.df.copy()\n",
    "        pd_df = pd_df[(((pd_df[\"Reference\"] == \"C\") & (pd_df[\"Allele\"] == \"T\")) | ((pd_df[\"Reference\"] == \"G\") & (pd_df[\"Allele\"] == \"A\")))]\n",
    "        pd_df = pd.concat([pd_df, chr_starts_df], ignore_index=True).sort_values(by=[\"Chromosome\", \"Region\"])\n",
    "        pd_df = renameChrToRoman(pd_df, \"Chromosome\")\n",
    "        palette = {\"C\": \"tab:blue\", \"G\": \"tab:red\", 'NaN': \"tab:gray\", \"T\": \"tab:gray\", \"A\": \"tab:gray\"}\n",
    "        sns.scatterplot(ax=ax, data=pd_df, x=\"Region\", y=\"Chromosome\", marker=\"|\", s=120, alpha=1, zorder=3, linewidth=1.5, hue=\"Reference\", palette=palette)\n",
    "\n",
    "        switches_df = SampleTable_Object.switchesTable.copy()\n",
    "        switches_df = switches_df[switches_df[\"Chromosome\"] != \"ref|NC_001224|\"]\n",
    "        switches_df = pd.concat([switches_df, starts_switches], ignore_index=True)\n",
    "        switches_df = renameChrToRoman(switches_df, \"Chromosome\")\n",
    "        sns.scatterplot(ax=ax,data=switches_df, x=\"Switch_Center\", y=\"Chromosome\", color=\"black\", marker=2, s=120, zorder=0, linewidth=2.5, alpha=0.8)\n",
    "\n",
    "    elif map_type==\"combined\":\n",
    "        import numpy as np\n",
    "        from natsort import index_natsorted\n",
    "        from mayo.settings import centromeres as chr_centromeres\n",
    "\n",
    "        #first deal with the SNPs (swaps of parent 1 and parent 2)\n",
    "        pd_df = SampleTable_Object.parentalSNPs.copy()\n",
    "        pd_df_heterozygous = SampleTable_Object.df_SNPs_heterozygous.copy()\n",
    "        pd_df_heterozygous = pd.concat([pd_df_heterozygous, chr_starts_df], ignore_index=True)\n",
    "        pd_df_heterozygous = pd_df_heterozygous.sort_values(by=\"Chromosome\", key=lambda x: np.argsort(index_natsorted(pd_df_heterozygous[\"Chromosome\"])))\n",
    "        pd_df_heterozygous = renameChrToRoman(pd_df_heterozygous, \"Chromosome\")\n",
    "\n",
    "        pd_df = pd.concat([pd_df, chr_starts_df], ignore_index=True)\n",
    "        pd_df = pd_df.sort_values(by=\"Chromosome\", key=lambda x: np.argsort(index_natsorted(pd_df[\"Chromosome\"])))  \n",
    "        pd_df = renameChrToRoman(pd_df, \"Chromosome\")\n",
    "\n",
    "        palette = {\"parent_1\": sns.color_palette(\"deep\")[2], \"parent_2\": sns.color_palette(\"deep\")[3]}\n",
    "        #palette = {\"parent_1\": \"tab:green\", \"parent_2\": \"tab:red\"}\n",
    "        markers = {\"parent_1\": 3, \"parent_2\": 3}\n",
    "\n",
    "        sns.scatterplot(ax=ax, data=pd_df_heterozygous, x=\"Region\", y=\"Chromosome\", color=\"tab:gray\", marker=3, s=60, alpha=0.6,zorder=-1, linewidth=0.75)\n",
    "        sns.scatterplot(ax=ax, data=pd_df, x=\"Region\", y=\"Chromosome\", hue=\"Parent\", palette=palette, style=\"Parent\", markers=markers, s=70, alpha=0.7,zorder=-1, linewidth=0.75)\n",
    "\n",
    "        #second deal with the SNVs (A3A)\n",
    "        label_dict = {\n",
    "            \"cen\": 'Centromere',\n",
    "            \"SPECTRA_STRANDWISE\": \"Reference Allele\",\n",
    "            \"Position\": \"Position\",\n",
    "            \"G\": \"G→N\",\n",
    "            \"C\": \"C→N\",\n",
    "            \"A\": \"A→N\",\n",
    "            \"T\": \"T→N\",\n",
    "            \"C_to_T\": \"C→T\",\n",
    "            \"C_to_A\": \"C/G→V/B\",\n",
    "            \"C_to_G\": \"C/G→V/B\",\n",
    "\n",
    "            \"G_to_A\": \"G→A\",\n",
    "            \"G_to_C\": \"C/G→V/B\",\n",
    "            \"G_to_T\": \"C/G→V/B\",\n",
    "\n",
    "            'T_to_A': \"A/T→N\",\n",
    "            'T_to_C': \"A/T→N\",\n",
    "            'T_to_G': \"A/T→N\",\n",
    "            'A_to_C': \"A/T→N\",\n",
    "            'A_to_G': \"A/T→N\",\n",
    "            'A_to_T': \"A/T→N\",\n",
    "            }\n",
    "        markers = {\n",
    "            'cen': \"o\",\n",
    "            \"C_to_T\": \"$|$\",\n",
    "            \"C_to_A\": \"$|$\",\n",
    "            \"C_to_G\": \"$|$\",\n",
    "\n",
    "            \"G_to_A\": \"$|$\",\n",
    "            \"G_to_C\": \"$|$\",\n",
    "            \"G_to_T\": \"$|$\",\n",
    "\n",
    "            'T_to_A': \"$|$\",\n",
    "            'T_to_C': \"$|$\",\n",
    "            'T_to_G': \"$|$\",\n",
    "            'A_to_C': \"$|$\",\n",
    "            'A_to_G': \"$|$\",\n",
    "            'A_to_T': \"$|$\",\n",
    "            }\n",
    "        palette = {\n",
    "            'cen': \"white\",\n",
    "            \"C_to_T\": \"tab:red\",\n",
    "            \"C_to_A\": \"tab:olive\",\n",
    "            \"C_to_G\": \"tab:olive\",\n",
    "\n",
    "            \"G_to_A\": \"tab:blue\",\n",
    "            \"G_to_C\": \"tab:olive\",\n",
    "            \"G_to_T\": \"tab:olive\",\n",
    "\n",
    "            'A_to_C': \"tab:gray\",\n",
    "            'A_to_G': \"tab:gray\",\n",
    "            'A_to_T': \"tab:gray\",\n",
    "\n",
    "            'T_to_A': \"tab:gray\",\n",
    "            'T_to_C': \"tab:gray\",\n",
    "            'T_to_G': \"tab:gray\"\n",
    "            }\n",
    "\n",
    "        df_SNVs = SampleTable_Object.df.copy()\n",
    "\n",
    "        try:\n",
    "            df_SNVs[\"SPECTRA_STRANDWISE\"] = df_SNVs.apply(lambda x: findSpectraStrandwise(x[\"Reference\"], x[\"Allele\"]), axis=1)\n",
    "        except:\n",
    "            logging.error(f\"Error in findSpectraStrandwise function. Skipping sample {SampleTable_Object.name}. The sample dataframe might be empty (size: {len(df_SNVs)}).\")\n",
    "            plt.close()\n",
    "            return\n",
    "\n",
    "\n",
    "        #df_SNVs = pd.concat([df_SNVs, chr_starts_df], ignore_index=True).sort_values(by=[\"Chromosome\", \"Region\"])\n",
    "        df_SNVs = renameChrToRoman(df_SNVs, \"Chromosome\")\n",
    "        chr_centromeres = renameChrToRoman(chr_centromeres, \"Chromosome\", \"numeric\")\n",
    "        df_SNVs = pd.concat([df_SNVs, chr_centromeres], ignore_index=True)\n",
    "        df_SNVs = df_SNVs.sort_values(by=\"Chromosome\", key=lambda x: np.argsort(index_natsorted(df_SNVs[\"Chromosome\"])))    \n",
    "\n",
    "        sns.scatterplot(ax=ax, data=df_SNVs[df_SNVs[\"Reference\"].isin([\"cen\"])], x=\"Region\", y=\"Chromosome\", hue=\"SPECTRA_STRANDWISE\", palette=palette, style=\"SPECTRA_STRANDWISE\", markers=markers, s=100, alpha=1,zorder=2, linewidth=0.75, edgecolor=\"black\")\n",
    "        sns.scatterplot(ax=ax, data=df_SNVs[~df_SNVs[\"Reference\"].isin([\"cen\"])], x=\"Region\", y=\"Chromosome\", hue=\"SPECTRA_STRANDWISE\", palette=palette, style=\"SPECTRA_STRANDWISE\", markers=markers, s=100, alpha=0.9,zorder=3, linewidth=0.05, edgecolor=\"black\")\n",
    "        #sns.scatterplot(ax=ax, data=df_SNVs, x=\"Region\", y=\"Chromosome\", marker=\"|\", s=120, alpha=1, zorder=3, linewidth=1.5, hue=\"Reference\", palette=palette)\n",
    "\n",
    "        switches_df = SampleTable_Object.switchesTable.copy()\n",
    "        switches_df = switches_df[switches_df[\"Chromosome\"] != \"ref|NC_001224|\"]\n",
    "        switches_df = pd.concat([switches_df, starts_switches], ignore_index=True)\n",
    "        switches_df = renameChrToRoman(switches_df, \"Chromosome\")\n",
    "        sns.scatterplot(ax=ax,data=switches_df, x=\"Switch_Center\", y=\"Chromosome\", color=\"black\", marker=3, s=90, zorder=-2, linewidth=0.75, alpha=0.70)\n",
    "        \n",
    "        df_recEvents = RecEventsTable_from_GC_CO_dict(SampleTable_Object.GC_dict, SampleTable_Object.CO_dict)\n",
    "        #remove heterozygous chromosomes from the recombination events; they are not informative/reliable there\n",
    "        heterozygous_chr = SampleTable_Object.heterozygous_chromosomes\n",
    "\n",
    "        if len(df_recEvents) != 0:\n",
    "            df_recEvents = df_recEvents[~df_recEvents[\"Chromosome\"].isin(heterozygous_chr)]\n",
    "            df_recEvents = pd.concat([df_recEvents, chr_starts_df], ignore_index=True)\n",
    "            df_recEvents = renameChrToRoman(df_recEvents, \"Chromosome\")\n",
    "            palette_recEvents = {\"GC\": \"tab:blue\", \"CO\": \"tab:red\"}\n",
    "            sns.scatterplot(ax=ax, data=df_recEvents, x=\"Region\", y=\"Chromosome\", hue=\"Type\", palette=palette_recEvents, marker=11, s=16, zorder=2, linewidth=0.5, alpha=0.7)\n",
    "            add_GC_CO_legend_to_ax(ax, palette_recEvents)\n",
    "\n",
    "        if cluster_kind is None:\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            #pval_list must be ordered from largest to smallest pvalue to make sense in the legend\n",
    "\n",
    "            if cluster_kind == \"PMACD\":\n",
    "                pval_list = ['p05', 'p01', 'p005', 'p001_def'] #'p0005', #'p0001']\n",
    "                pval_list.reverse()\n",
    "            \n",
    "            elif cluster_kind == \"JT\":\n",
    "                pval_list = [0.01, 0.001, 0.0001, 0.00001]\n",
    "                pval_list.reverse()\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Cluster kind {cluster_kind} is not supported. Please choose from 'JT' or 'PMACD'.\")\n",
    "\n",
    "            save_name_suffix += f\"_{cluster_kind}_clusters\"\n",
    "            add_clusters_patch_to_ax(ax, pval_list, SampleTable_Object, clusters_kind=cluster_kind)\n",
    "\n",
    "    else: #just clusters\n",
    "        pd_df = SampleTable_Object.df_SNPs.copy()\n",
    "\n",
    "        pd_df = pd.concat([pd_df, chr_starts_df], ignore_index=True).sort_values(by=[\"Chromosome\", \"Region\"])\n",
    "        pd_df = renameChrToRoman(pd_df, \"Chromosome\")\n",
    "        palette = {True: \"blue\", False: \"red\"}\n",
    "        sns.scatterplot(ax=ax, data=pd_df, x=\"Region\", y=\"Chromosome\", marker=\"|\", s=120, alpha=1, zorder=3, linewidth=1.5, hue='Clustered_Proximal', palette=palette) #hue='Switch_Proximal', Is_Clustered, Clustered_Proximal\n",
    "\n",
    "        switches_df = SampleTable_Object.switchesTable.copy()\n",
    "        switches_df = switches_df[switches_df[\"Chromosome\"] != \"ref|NC_001224|\"]\n",
    "        switches_df = pd.concat([switches_df, starts_switches], ignore_index=True)\n",
    "        switches_df = renameChrToRoman(switches_df, \"Chromosome\")\n",
    "        sns.scatterplot(ax=ax,data=switches_df, x=\"Switch_Center\", y=\"Chromosome\", color=\"black\", marker=2, s=120, zorder=0, linewidth=1.5, alpha=0.8)\n",
    "\n",
    "    ax.set_xlabel(\"POSITION\")\n",
    "    ax.set_ylabel(\"CHROMOSOME\")\n",
    "\n",
    "    if map_type==\"combined\":\n",
    "\n",
    "        #dont repeat the same item in the legend\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        by_label = dict(zip(labels, handles))\n",
    "        #order the legend\n",
    "        legend_order = [\"cen\", \"Position\", \"C_to_T\", \"G_to_A\", \"C_to_A\", \"C_to_G\", \"G_to_C\", \"G_to_T\", \"T_to_A\", \"T_to_C\", \"T_to_G\", \"A_to_C\", \"A_to_G\", \"A_to_T\"]\n",
    "\n",
    "        #relable the legend texts according to the legend_order\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                by_label = {label_dict.get(key): by_label[key] for key in legend_order}\n",
    "                break\n",
    "\n",
    "            except Exception as e:\n",
    "                try:\n",
    "                    logging.warning(f\"Could not relabel legend. {e}. Removing {e} from legend_order and trying again.\")\n",
    "                    #extract the string from the error message\n",
    "                    e = str(e).split(\"'\")[1]\n",
    "                    legend_order = [x for x in legend_order if x != str(e)]\n",
    "                except Exception as e:\n",
    "                    logging.warning(f\"Cound not relabel legend. {e}.\")\n",
    "                    break\n",
    "\n",
    "        ax.legend(by_label.values(), by_label.keys(), fontsize=10, loc='lower right', bbox_to_anchor=(0.98, 0.05), title=None)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "\n",
    "    else:\n",
    "\n",
    "        legend_texts = plt.legend().get_texts()\n",
    "        for i in range(len(legend_texts)):\n",
    "            label_str = legend_texts[i].get_text()\n",
    "            #remove NaNs from legend\n",
    "            if label_str == \"NaN\":\n",
    "                legend_texts[i].set_text(\"\")\n",
    "            if label_str in label_dict:\n",
    "                new_label = label_dict.get(label_str)\n",
    "\n",
    "                legend_texts[i].set_text(new_label)\n",
    "    \n",
    "    if saveMap:\n",
    "        if not os.path.exists(f'figures/tests/{map_type}'):\n",
    "            os.makedirs(f'figures/tests/{map_type}')\n",
    "        plt.savefig(f'figures/{map_type}/{title}_{map_type}{save_name_suffix}.png', transparent=False, dpi=600)\n",
    "\n",
    "    if showMap:\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        # close the plot\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (optional) draw a combined map of SNPs, Switches, Mutations, and Clusters (at different p-values) for each sample\n",
    "\n",
    "for index, i in enumerate(samples_SNVs):\n",
    "\n",
    "    print(i.heterozygous_chromosomes)\n",
    "\n",
    "    if i.name == samples_parental_SNPs[index].name:\n",
    "        print(f\"Processing sample {i.name}...\")\n",
    "        i.parentalSNPs = samples_parental_SNPs[index].output_df.copy()\n",
    "        i.df_SNPs_heterozygous = samples_parental_SNPs[index].df_SNPs_heterozygous.copy()\n",
    "        \n",
    "    else:\n",
    "        print(\"ERROR: sample names do not match!\")\n",
    "        print(f\"{i.name} != {samples_parental_SNPs[index].name}\")\n",
    "        break\n",
    "\n",
    "    drawSNPMap(i, df_chr, starts, saveMap=True, showMap=True, map_type=\"combined\", save_name_suffix=f\"_{SNP_NUM}snp\", cluster_kind=CLUSTER_TYPE_ANALYSIS)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_name_clusters_null = f\"3x_proximal_{CLUSTER_TYPE_ANALYSIS}_clusters_haploid_setting_{SNP_NUM}snp.csv\"\n",
    "\n",
    "\n",
    "samples_SNVs[:] = [df for df in samples_SNVs if df.name in (haploid_samples_ung1d)]\n",
    "logging.info(\"Created a subset of samples for simulation (samples_SNVs)\")\n",
    "\n",
    "switches_list[:] = [df for df in switches_list if df.name in (haploid_samples_ung1d)]\n",
    "logging.info(\"Created a subset of samples for simulation (switches_list)\")\n",
    "\n",
    "total_clusters = 0\n",
    "for i in samples_SNVs:\n",
    "    i_clusters = i.df_SNPs[\"Cluster_ID\"].nunique()\n",
    "    total_clusters += i_clusters\n",
    "    logging.info(f\"{i.name} has {i_clusters} clusters\")\n",
    "logging.info(f\"######## Total number of clusters in the simulation dataset: {total_clusters} ########\")\n",
    "\n",
    "proximal_clusters = conductNullHypothesisSimulation(switches_list, chromosomes, samples_SNVs, simulation_generations=3, save_file_name=save_file_name_clusters_null)\n",
    "logging.info(f'Finished writing everything to the file: {save_file_name_clusters_null}')\n",
    "logging.info('Completed null hypothesis simulation')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
